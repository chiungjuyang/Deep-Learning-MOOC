{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主題 01-3. 作業: 改造你的 1 號神經網路\n",
    "\n",
    "本週的作業很簡單, 就是把上課手寫辨識的範例改造一下, 看能不能讓成效變得更好。因為是第一次作業, 我們不特別要求要達到什麼水準, 只要「測試資料」的正確率還在 9 成以上就可以。我們這美好的 MNIST 例子, 你基本上亂亂作都是可以達成的, 不用擔心!\n",
    "\n",
    "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備\n",
    "\n",
    "這裡是一樣的我們不再說明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再來是我們標準數據分析動作!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "這裡也是一樣的! 好消息是如果你之前跟著做過, 現在會快很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 改造你的神經網路\n",
    "\n",
    "### 3.1 改變結構\n",
    "\n",
    "我們本來用了兩層的隱藏層, 你可以改不同層數試試。比方說, 你可以試真的「深度學習」, 也就是隱藏層加到 3 層或以上。不過你需要有電腦彷如當機的心理準備...\n",
    "\n",
    "另外也可改變神經元的數目。比如說本來是這樣設的一個隱藏層, 我們用了 500 個神經元是這樣寫的。\n",
    "\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "因此如果要改 520 個神經元, 就會像這樣:\n",
    "\n",
    "    model.add(Dense(520))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "是不是很簡單?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 換個 activation function!\n",
    "\n",
    "在 Keras 中要換個 activation function 很簡單, 比如說我們要換當巨星 ReLU, 就在每層設 activation function 時說就好了。\n",
    "\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalize 我們的數據\n",
    "\n",
    "我們的每筆輸入是 784 維的\n",
    "\n",
    "$$\\mathbf{x} = (x_1, x_2, \\ldots, x_{784})$$\n",
    "\n",
    "我們會說這個神經網路有 784 個 features。現在我們每一個 $x_i$ 都是 0 到 255 的整數, 我們常喜歡把每個 $x_i$ 壓縮到一個更小的範圍, 一般有兩種作法:\n",
    "\n",
    "1. 每個 $x_i$ 都壓到 [0,1] 中的一個數\n",
    "2. 讓每個 $x_i$ 由平均值是 0, 標準差是 1 的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們的例子來做做看!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以試試看就知道, 真的都壓到 0-1 之間的數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "還是可以畫的哦! 指令和以前完全一樣!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbccafe42e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[87], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把輸入的資料做 normalization 是很好的習慣。原因有好幾個, 比方說:\n",
    "\n",
    "1. 每個 feature 範圍不同時, 常常會由數值大的主導。Normalization 可以避免這種事情發生。\n",
    "2. 因為像 ReLU 在大於零的部份就是 $f(x) = x$ 這樣的函數, $x$ 越大, 值就越大, 甚至非常大。\n",
    "3. 再來是穩定性的問題, 神經網路的學理研究就喜歡把所有 feature, 所有 weight 都假設在「平均值 0, 標準差 1」的常態分布。這樣的狀況也證實有各種良好特質。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 優化方式的調整\n",
    "\n",
    "### 5.1 改善學習方式的兩大考量\n",
    "\n",
    "我們用 SGD 可以說是最標準的方式, 事實上所有優化 (學習) 方式基本上都是 gradient descent。不過我們有兩大方向可以考量改善:\n",
    "\n",
    "#### (1) 加入 momentum\n",
    "\n",
    "想像我們的 loss function 畫出來像一座高低起伏的山, 我們在山中的某一個點, 想要走到山下。Gradient descent 會帶我們從「目前看到下坡最陡的方向」下山。但是走了兩步後我們可能發現 gradient descent 又說要走另一個方向。於是在那繞來繞去才終於下山。因此我們想要以更「穩定而勇敢」的方式, 比較朝向一個目標前進, 就加入所謂的 momentum。\n",
    "\n",
    "#### (2) learning rate 變速器\n",
    "\n",
    "我們說 learning rate 調夠小, 我們的神經網路基本上都該收斂的。不過調太小可能學非常慢, 大了一點又怕跳過頭。於是有一些「變速」的方式被研發出來, 一般的原則就是「開始快、接近目標時變慢」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 在 Keras 選用不同學習法!\n",
    "\n",
    "\n",
    "我們就先 import 想要的學習法, 如果不知道可以考慮用 Adam, 前兩大項考量 Adam 都有考慮進去!\n",
    "\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "然後在 compile 時說要用 Adam 即可。\n",
    "\n",
    "    model.compile(loss='mse', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "Adam 其實有些參數可調, 但我們這暫不多談。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf2py38]",
   "language": "python",
   "name": "conda-env-tf2py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
