{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主題 01-1. 標準的 Fully Connected (Dense) NN\n",
    "\n",
    "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。除此之外的小細節包括:\n",
    "\n",
    "1. `predict_class` 已改直接 `predict` 取 `argmax`。\n",
    "2. Learning rate 參數要叫 `learning_rate`, 不再用 `lr`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們標準數據分析動作!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫\n",
    "\n",
    "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 由 tf.Keras 讀入 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一次要花點時間)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看看訓練資料是不是 6 萬筆、測試資料是不是有 1 筆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特別要注意的是, 萬一在讀的過程中失敗, 你需要找到下載的部份數據集刪去, 然後在一個網路通𣈱的地方再下載一次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 數據庫的內容\n",
    "\n",
    "每筆輸入 (x) 就是一個手寫的 0-9 中一個數字的圖檔, 大小為 28x28。而輸出 (y) 當然就是「正確答案」。我們來看看編號 87 的訓練資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        125, 225, 254, 254, 255, 254, 170,  48,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 101, 250,\n",
       "        253, 253, 253, 253, 253, 253, 253, 250, 161,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  94, 246, 247, 253,\n",
       "        253, 196, 227, 116,  56, 253, 253, 253, 234,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 152, 253, 253, 180,\n",
       "         19,   9,  15,   0,   4,  55, 253, 253, 166,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  41, 238, 253, 253, 125,\n",
       "          0,   0,   0,  21, 189, 232, 253, 253, 117,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 219, 253, 220, 165,  34,\n",
       "         92,  21,  52, 228, 253, 253, 241,  82,  13,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  38, 241, 170,  25,  20,  12,\n",
       "         75,  39,  59, 253, 253, 253, 110,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 112, 253, 236,  67,   0,   0,\n",
       "          0,   0, 100, 253, 253, 221,  16,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  23, 239, 253, 235, 202, 135,\n",
       "         99, 173, 240, 253, 253, 110,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  54, 200, 253, 253, 253,\n",
       "        253, 253, 253, 253, 241,  63,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 112, 244, 253,\n",
       "        237, 142, 253, 253, 111,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61,  71,\n",
       "         51, 159, 253, 188,  22,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15,\n",
       "        150, 236, 212,  22,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  99,\n",
       "        253, 243,  98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 237,\n",
       "        253, 105,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10, 219, 253,\n",
       "        195,  22,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8, 171, 253, 207,\n",
       "         21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 105, 253, 198,  76,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  60, 242, 253,  38,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 235, 253, 206,  19,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為是圖檔, 當然可以顯示出來!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa133fd9d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 輸入格式整理\n",
    "\n",
    "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 輸出格式整理\n",
    "\n",
    "我們可能會想, 我們想學的函數是這樣的型式:\n",
    "\n",
    "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}$$\n",
    "\n",
    "其實這樣不太好! 為什麼呢? 比如說我們的輸入 x 是一張 0 的圖, 因為我們訓練的神經網路總會有點誤差, 所以可能會得到:\n",
    "\n",
    "$$\\hat{f}(x) = 0.5$$\n",
    "\n",
    "那這意思是有可能是 0, 也有可能是 1 嗎!!?? 可是 0 和 1 根本不像啊。換句話說分類的問題這樣做其實不合理!\n",
    "\n",
    "於是我們會做 \"1-hot enconding\", 也就是\n",
    "\n",
    "* 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "* 5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "等等。因為分類問題基本上都要做這件事, Keras 其實已幫我們準備好套件!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看看剛剛是 9 的 87 號數據的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和我們想的一樣! 至此我們可以打造我們的神經網路了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 打造第一個神經網路\n",
    "\n",
    "我們決定了我們的函數是\n",
    "\n",
    "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}^{10}$$\n",
    "\n",
    "這個樣子。而我們又說第一次要用標準神網路試試, 所以我們只需要再決定要幾個隱藏層、每層要幾個神經元, 用哪個激發函數就可以了。\n",
    "\n",
    "### 3.1 決定神經網路架構、讀入相關套件\n",
    "\n",
    "假如我們要這麼做:\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* Hidden layer 1 用 <span style=\"color:red;\">4</span> 個神經元\n",
    "* Hidden layer 2 用 <span style=\"color:red;\">2</span> 個神經元\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span>\n",
    "\n",
    "於是從 tf.Keras 把相關套件讀進來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 建構我們的神經網路\n",
    "\n",
    "和以前做迴歸或機器學習一樣, 我們就打開個「函數學習機」。標準一層一層傳遞的神經網路叫 `Sequential`, 於是我們打開一個空的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們每次用 `add` 去加一層, 從第一個隱藏層開始。而第一個隱藏層因為 Keras 當然猜不到輸入有幾個 features, 所以我們要告訴它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二層 hidden layer 因為前面輸出是 4, 現在輸入是 2, 就不用再說了! 這裡的 2 只告訴 Keras, 我們第二層是用 2 個神經元!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出有 10 個數字, 所以輸出層的神經元是 10 個! 而如果我們的網路輸出是 \n",
    "\n",
    "$$(y_1, y_2, \\ldots, y_{10})$$\n",
    "\n",
    "我們還希望\n",
    "\n",
    "$$\\sum_{i=1}^{10} y_i = 1$$\n",
    "\n",
    "這可能嗎, 結果是很容易, 就用 `softmax` 當激發函數就可以!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此我們的第一個神經網路就建好了!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 組裝\n",
    "\n",
    "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。你可以發現我們還需要做幾件事:\n",
    "\n",
    "* 決定使用的 loss function, 一般是 `mse`\n",
    "* 決定 optimizer, 我們用標準的 SGD\n",
    "* 設 learning rate\n",
    "\n",
    "為了一邊訓練一邊看到結果, 我們加設\n",
    "\n",
    "    metrics=['accuracy']\n",
    "    \n",
    "本行基本上和我們的神經網路功能沒有什麼關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.087), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以檢視我們神經網路的架構, 可以確認一下是不是和我們想像的一樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 看 model 的 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 3140      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,180\n",
      "Trainable params: 3,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很快算算參數數目和我們想像是否是一樣的!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3140"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*4 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*10 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 訓練你的第一個神經網路\n",
    "\n",
    "恭喜! 我們完成了第一個神經網路。現在要訓練的時候, 你會發現不是像以前沒頭沒腦把訓練資料送進去就好。這裡我們還有兩件事要決定:\n",
    "\n",
    "* 一次要訓練幾筆資料 (`batch_size`), 我們就 100 筆調一次參數好了\n",
    "* 這 6 萬筆資料一共要訓練幾次 (`epochs`), 我們訓練個 20 次試試\n",
    "\n",
    "於是最精彩的就來了。你要有等待的心理準備..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.1144\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.1129\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.1102\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.1100\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.1162\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0894 - accuracy: 0.1665\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0893 - accuracy: 0.1778\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0892 - accuracy: 0.1822\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.1904\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.1928\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.1935\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0889 - accuracy: 0.1961\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.1973\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0887 - accuracy: 0.1998\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0885 - accuracy: 0.2061\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.2059\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0882 - accuracy: 0.2095\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0881 - accuracy: 0.2060\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0879 - accuracy: 0.2091\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0878 - accuracy: 0.2078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa12c04e3d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 試用我們的結果\n",
    "\n",
    "我們來用比較炫的方式來看看可愛的神經網路學習成果。對指令有問題可以參考我們之前的 MOOC 影片教學。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們 \"predict\" 放的是我們神經網路的學習結果。這裡用 `predict_classes` 會讓我們 Keras 選 10 個輸出機率最大的那類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.argmax(model.predict(x_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 1, 1, ..., 7, 7, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要忘了我們的 `x_test` 每筆資料已經換成 784 維的向量, 我們要整型回 28x28 的矩陣才能當成圖形顯示出來!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(測試編號):\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28), cmap='Greys')\n",
    "    print('神經網路判斷為:', y_predict[測試編號])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路判斷為: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041d9206818649308bbc25f406dfb76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='測試編號', max=9999), Button(description='Run Interact', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(測試編號)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(test, 測試編號=(0, 9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到底測試資料總的狀況如何呢? 我們可以給我們神經網路「考一下試」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 897us/step - loss: 0.0876 - accuracy: 0.2075\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08757687360048294\n",
      "正確率 0.20749999582767487\n"
     ]
    }
   ],
   "source": [
    "print('loss:', score[0])\n",
    "print('正確率', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [作業] \n",
    "\n",
    "這個神經網路實在有夠遜的! 我們試試看能不能改善它, 讓正確率提升到 90% 以上! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 訓練好的神經網路存起來!\n",
    "\n",
    "如果對訓練成果滿意, 我們當然不想每次都再訓練一次! 我們可以把神經網路的架構和訓練好的參數都存起來, 以供日後使用!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前還沒裝 pyh5 要在終端機 (Anaconda Prompt) 下安裝:\n",
    "    \n",
    "    conda install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('stupid_model.json', 'w').write(model_json)\n",
    "model.save_weights('stupid_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf2py38]",
   "language": "python",
   "name": "conda-env-tf2py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
